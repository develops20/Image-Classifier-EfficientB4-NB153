{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104830,"databundleVersionId":12628243,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm import tqdm\nimport cv2\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.cuda.amp as amp\nfrom torch.cuda.amp import GradScaler\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms, models\nimport torchvision.transforms as transforms\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\n# Enhanced Configuration\nclass Config:\n    # Paths\n    DATA_PATH = '/kaggle/input/sheep-classification-challenge-2025/Sheep Classification Images'\n    TRAIN_DIR = os.path.join(DATA_PATH, 'train')\n    TEST_DIR = os.path.join(DATA_PATH, 'test')\n    TRAIN_CSV = os.path.join(DATA_PATH, 'train_labels.csv')\n    \n    # Enhanced Model parameters\n    IMG_SIZE = 456  # Increased from 380 - better resolution helps\n    BATCH_SIZE = 6  # Reduced to allow larger images\n    NUM_EPOCHS = 100  # Increased epochs\n    LEARNING_RATE = 2e-5  # Lower learning rate for fine-tuning\n    NUM_CLASSES = 7\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Enhanced Early stopping\n    EARLY_STOPPING_PATIENCE = 15  # Increased patience\n    MIN_DELTA = 0.0005  # More sensitive improvement detection\n    \n    # Breeds\n    BREEDS = ['Naeimi', 'Najdi', 'Harri', 'Goat', 'Sawakni', 'Roman', 'Barbari']\n    \n    # Enhanced model architecture\n    MODEL_NAME = 'efficientnet_b5'  # Upgraded from B4 to B5\n    \n    # Cross-validation folds\n    N_FOLDS = 5\n\nconfig = Config()\n\nprint(f\"Using device: {config.DEVICE}\")\nprint(f\"Enhanced configuration: {config.IMG_SIZE}px, {config.MODEL_NAME}\")\n\n# Enhanced Data Augmentation\ndef get_enhanced_transforms():\n    \"\"\"Enhanced data augmentation for better generalization\"\"\"\n    train_transform = transforms.Compose([\n        transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n        # Transforms that operate on PIL Images go first\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.2),\n        transforms.RandomRotation(degrees=20),\n        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15),\n        transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.85, 1.15)),\n        transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n        \n        # Convert to Tensor BEFORE operations that require tensors (like RandomErasing)\n        transforms.ToTensor(),\n        \n        # Transforms that operate on Tensors go after ToTensor()\n        transforms.RandomErasing(p=0.2, scale=(0.02, 0.1)), # This now operates on a tensor\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    val_transform = transforms.Compose([\n        transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    return train_transform, val_transform\n    \n# def get_enhanced_transforms():\n#     \"\"\"Enhanced data augmentation for better generalization\"\"\"\n#     train_transform = transforms.Compose([\n#         transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n#         # More aggressive augmentations\n#         transforms.RandomHorizontalFlip(p=0.5),\n#         transforms.RandomVerticalFlip(p=0.2),  # New\n#         transforms.RandomRotation(degrees=20),  # Increased\n#         transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15),  # Enhanced\n#         transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.85, 1.15)),  # Enhanced\n#         transforms.RandomPerspective(distortion_scale=0.2, p=0.3),  # New\n#         transforms.RandomErasing(p=0.2, scale=(0.02, 0.1)),  # New - helps with overfitting\n#         transforms.ToTensor(),\n#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n#     ])\n    \n#     val_transform = transforms.Compose([\n#         transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n#         transforms.ToTensor(),\n#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n#     ])\n    \n#     return train_transform, val_transform\n\ndef get_enhanced_tta_transforms():\n    \"\"\"Enhanced TTA with more variations\"\"\"\n    tta_transforms = [\n        # Original\n        transforms.Compose([\n            transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        # Horizontal flip\n        transforms.Compose([\n            transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n            transforms.RandomHorizontalFlip(p=1.0),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        # Rotation variants\n        transforms.Compose([\n            transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n            transforms.RandomRotation(degrees=(5, 5)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        transforms.Compose([\n            transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n            transforms.RandomRotation(degrees=(-5, -5)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        # Brightness variants\n        transforms.Compose([\n            transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n            transforms.ColorJitter(brightness=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ]),\n        # Scale variants\n        transforms.Compose([\n            transforms.Resize((int(config.IMG_SIZE * 1.05), int(config.IMG_SIZE * 1.05))),\n            transforms.CenterCrop(config.IMG_SIZE),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    ]\n    return tta_transforms\n\n\nclass EnhancedSheepClassifier(nn.Module):\n    def __init__(self, num_classes=7, model_name='efficientnet_b5'):\n        super(EnhancedSheepClassifier, self).__init__()\n        \n        if model_name == 'efficientnet_b5':\n            self.backbone = models.efficientnet_b5(weights=models.EfficientNet_B5_Weights.IMAGENET1K_V1)\n            # Get the number of features right before the final classification layer\n            in_features = self.backbone.classifier[1].in_features\n            \n            # Replace the classifier with a more robust head.\n            # The backbone already handles AdaptiveAvgPool2d and Flatten internally.\n            # So, we directly use the in_features for our custom layers.\n            self.backbone.classifier = nn.Sequential(\n                nn.BatchNorm1d(in_features), # Input here should be (batch_size, in_features)\n                nn.Dropout(0.4),\n                nn.Linear(in_features, 1024),\n                nn.BatchNorm1d(1024),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.4),\n                nn.Linear(1024, 512),\n                nn.BatchNorm1d(512),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.3),\n                nn.Linear(512, num_classes)\n            )\n        elif model_name == 'efficientnet_b4':\n            self.backbone = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n            in_features = self.backbone.classifier[1].in_features\n            self.backbone.classifier = nn.Sequential(\n                nn.BatchNorm1d(in_features),\n                nn.Dropout(0.4),\n                nn.Linear(in_features, 768),\n                nn.BatchNorm1d(768),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.3),\n                nn.Linear(768, 384),\n                nn.BatchNorm1d(384),\n                nn.ReLU(inplace=True),\n                nn.Dropout(0.2),\n                nn.Linear(384, num_classes)\n            )\n\n    def forward(self, x):\n        return self.backbone(x)\n\n# Enhanced Dataset Class\nclass EnhancedSheepDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n        self.df = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n        \n        if not is_test:\n            self.label_encoder = LabelEncoder()\n            self.labels = self.label_encoder.fit_transform(self.df['label'])\n            self.label_to_idx = {label: idx for idx, label in enumerate(self.label_encoder.classes_)}\n            self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        filename = self.df.iloc[idx]['filename']\n        img_path = os.path.join(self.img_dir, filename)\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n            # Enhanced image preprocessing\n            image = self.enhance_image_quality(image)\n        except Exception as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            image = Image.new('RGB', (config.IMG_SIZE, config.IMG_SIZE), (0, 0, 0))\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_test:\n            return image, filename\n        else:\n            label = self.labels[idx]\n            return image, label\n    \n    def enhance_image_quality(self, image):\n        \"\"\"Apply basic image enhancement\"\"\"\n        # Convert to numpy for processing\n        img_array = np.array(image)\n        \n        # Slight contrast enhancement\n        img_array = np.clip(img_array * 1.05, 0, 255).astype(np.uint8)\n        \n        return Image.fromarray(img_array)\n\n# Cross-Validation Training\ndef cross_validate_model(train_df):\n    \"\"\"Perform stratified k-fold cross-validation\"\"\"\n    skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=42)\n    fold_scores = []\n    fold_models = []\n    \n    train_transform, val_transform = get_enhanced_transforms()\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n        print(f\"\\n{'='*20} FOLD {fold+1}/{config.N_FOLDS} {'='*20}\")\n        \n        fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n        fold_val_df = train_df.iloc[val_idx].reset_index(drop=True)\n        \n        # Create datasets\n        train_dataset = EnhancedSheepDataset(fold_train_df, config.TRAIN_DIR, train_transform)\n        val_dataset = EnhancedSheepDataset(fold_val_df, config.TRAIN_DIR, val_transform)\n        \n        train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2)\n        val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n        \n        # Initialize model\n        model = EnhancedSheepClassifier(num_classes=config.NUM_CLASSES, model_name=config.MODEL_NAME)\n        model = model.to(config.DEVICE)\n        \n        # Calculate class weights\n        train_labels_numerical = train_dataset.labels\n        class_weights_array = compute_class_weight(\n            class_weight='balanced',\n            classes=np.unique(train_labels_numerical),\n            y=train_labels_numerical\n        )\n        if config.DEVICE.type == 'cuda':\n            class_weights_tensor = torch.tensor(class_weights_array, dtype=torch.float16).to(config.DEVICE)\n        else:\n            class_weights_tensor = torch.tensor(class_weights_array, dtype=torch.float32).to(config.DEVICE)\n        # class_weights_tensor = torch.tensor(class_weights_array, dtype=torch.float).to(config.DEVICE)\n        \n        # Enhanced optimizer and scheduler\n        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)  # Label smoothing\n        optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=2e-4)\n        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n        \n        # Train fold\n        best_model, best_f1 = train_single_fold(model, train_loader, val_loader, criterion, optimizer, scheduler, fold)\n        \n        fold_scores.append(best_f1)\n        fold_models.append(best_model)\n        \n        print(f\"Fold {fold+1} Best F1: {best_f1:.4f}\")\n    \n    print(f\"\\nCross-Validation Results:\")\n    print(f\"Mean F1: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")\n    print(f\"Individual Fold Scores: {[f'{score:.4f}' for score in fold_scores]}\")\n    \n    return fold_models, fold_scores\n\ndef train_single_fold(model, train_loader, val_loader, criterion, optimizer, scheduler, fold):\n    \"\"\"Train a single fold\"\"\"\n    best_f1 = 0.0\n    best_model_state = None\n    patience_counter = 0\n    scaler = GradScaler()\n    \n    for epoch in range(config.NUM_EPOCHS):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        \n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(config.DEVICE), target.to(config.DEVICE)\n            \n            optimizer.zero_grad()\n            with amp.autocast():\n                output = model(data)\n                loss = criterion(output, target)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += loss.item()\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        all_preds = []\n        all_targets = []\n        \n        with torch.no_grad():\n            for data, target in val_loader:\n                data, target = data.to(config.DEVICE), target.to(config.DEVICE)\n                with amp.autocast():\n                    output = model(data)\n                val_loss += criterion(output, target).item()\n                \n                _, predicted = torch.max(output.data, 1)\n                all_preds.extend(predicted.cpu().numpy())\n                all_targets.extend(target.cpu().numpy())\n        \n        f1 = f1_score(all_targets, all_preds, average='macro')\n        \n        if f1 > best_f1:\n            best_f1 = f1\n            best_model_state = model.state_dict().copy()\n            patience_counter = 0\n            print(f\"Fold {fold+1}, Epoch {epoch+1}: New best F1 = {best_f1:.4f}\")\n        else:\n            patience_counter += 1\n        \n        scheduler.step()\n        \n        if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    # Load best model\n    model.load_state_dict(best_model_state)\n    return model, best_f1\n\n# Enhanced Ensemble Prediction\ndef ensemble_predict(models, test_df, label_encoder):\n    \"\"\"Make ensemble predictions using multiple models and TTA\"\"\"\n    tta_transforms = get_enhanced_tta_transforms()\n    all_predictions = []\n    \n    for model_idx, model in enumerate(models):\n        model.eval()\n        model_predictions = []\n        \n        print(f\"Generating predictions for model {model_idx+1}/{len(models)}...\")\n        \n        for idx in tqdm(range(len(test_df)), desc=f\"Model {model_idx+1}\"):\n            filename = test_df.iloc[idx]['filename']\n            img_path = os.path.join(config.TEST_DIR, filename)\n            \n            try:\n                image = Image.open(img_path).convert('RGB')\n                # Apply same enhancement as training\n                dataset = EnhancedSheepDataset(pd.DataFrame(), '', None, True)\n                image = dataset.enhance_image_quality(image)\n            except Exception as e:\n                print(f\"Error loading {img_path}: {e}\")\n                image = Image.new('RGB', (config.IMG_SIZE, config.IMG_SIZE), (0, 0, 0))\n            \n            tta_outputs = []\n            with torch.no_grad():\n                for tta_transform in tta_transforms:\n                    augmented_image = tta_transform(image).unsqueeze(0).to(config.DEVICE)\n                    with amp.autocast():\n                        output = model(augmented_image)\n                    tta_outputs.append(torch.softmax(output.float(), dim=1))\n            \n            # Average TTA predictions\n            avg_output = torch.mean(torch.cat(tta_outputs, dim=0), dim=0)\n            model_predictions.append(avg_output.cpu().numpy())\n        \n        all_predictions.append(np.array(model_predictions))\n    \n    # Ensemble averaging\n    ensemble_probs = np.mean(all_predictions, axis=0)\n    final_predictions = np.argmax(ensemble_probs, axis=1)\n    \n    # Convert to labels\n    pred_labels = label_encoder.inverse_transform(final_predictions)\n    \n    return test_df['filename'].values, pred_labels\n\n# Enhanced main function\ndef enhanced_main():\n    \"\"\"Enhanced main pipeline with cross-validation and ensemble\"\"\"\n    print(\"=== Enhanced Sheep Classification Pipeline ===\")\n    print(f\"Target: Top 10 (>0.98 F1)\")\n    print(f\"Enhanced Model: {config.MODEL_NAME} with {config.IMG_SIZE}px resolution\")\n    print(\"=\" * 60)\n    \n    # Load data\n    train_df = pd.read_csv(config.TRAIN_CSV)\n    print(f\"Training data: {train_df.shape}\")\n    print(f\"Class distribution:\\n{train_df['label'].value_counts()}\")\n    \n    # Cross-validation training\n    print(f\"\\nStarting {config.N_FOLDS}-fold cross-validation...\")\n    fold_models, fold_scores = cross_validate_model(train_df)\n    \n    # Prepare test data\n    test_files = [f for f in os.listdir(config.TEST_DIR) if f.endswith('.jpg')]\n    test_df = pd.DataFrame({'filename': test_files})\n    \n    # Get label encoder from first model (they should all be the same)\n    temp_dataset = EnhancedSheepDataset(train_df, config.TRAIN_DIR, None, is_test=False)\n    label_encoder = temp_dataset.label_encoder\n    \n    # Ensemble prediction\n    print(f\"\\nGenerating ensemble predictions on {len(test_df)} test images...\")\n    filenames, predictions = ensemble_predict(fold_models, test_df, label_encoder)\n    \n    # Create submission\n    submission_df = pd.DataFrame({\n        'filename': filenames,\n        'label': predictions\n    })\n    \n    submission_df.to_csv('enhanced_submission.csv', index=False)\n    \n    print(f\"\\nEnhanced Results:\")\n    print(f\"Cross-validation mean F1: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")\n    print(f\"Ensemble submission created: enhanced_submission.csv\")\n    print(f\"Test predictions: {len(predictions)}\")\n    print(f\"\\nPrediction distribution:\")\n    print(submission_df['label'].value_counts())\n    \n    return fold_models, submission_df, fold_scores\n\n# Run enhanced pipeline\nif __name__ == \"__main__\":\n    models, submission, scores = enhanced_main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:58:41.861483Z","iopub.execute_input":"2025-06-20T07:58:41.861843Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEnhanced configuration: 456px, efficientnet_b5\n=== Enhanced Sheep Classification Pipeline ===\nTarget: Top 10 (>0.98 F1)\nEnhanced Model: efficientnet_b5 with 456px resolution\n============================================================\nTraining data: (682, 2)\nClass distribution:\nlabel\nNaeimi     255\nGoat       107\nSawakni     80\nRoman       72\nNajdi       71\nHarri       62\nBarbari     35\nName: count, dtype: int64\n\nStarting 5-fold cross-validation...\n\n==================== FOLD 1/5 ====================\nFold 1, Epoch 1: New best F1 = 0.2347\nFold 1, Epoch 3: New best F1 = 0.3283\nFold 1, Epoch 4: New best F1 = 0.4320\nFold 1, Epoch 5: New best F1 = 0.4663\nFold 1, Epoch 6: New best F1 = 0.4675\nFold 1, Epoch 7: New best F1 = 0.5196\nFold 1, Epoch 10: New best F1 = 0.5418\nFold 1, Epoch 11: New best F1 = 0.6100\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}